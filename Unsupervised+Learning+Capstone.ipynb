{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import email\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizertfidfv = TfidfVectorizer(min_df=1,stop_words='english')\n",
    "#unique delim to separate columns without messing up content\n",
    "DELIMETER = chr(255)\n",
    "\n",
    "#needed because a few of the emails were too large for the default csv cell size\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set paths (currently pathing for remote AWS EC2 Instance)\n",
    "root_path = '/home/ubuntu/ssl/notebooks/data/maildir'\n",
    "saved_file = '/home/ubuntu/ssl/notebooks/processed enron emails.csv'\n",
    "testing_batch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_emails_into_df(origin, destination, testbool):\n",
    "    #safety check to see if the file has been created so I don't overwrite a finished file\n",
    "    already_processed = os.path.isfile(destination) \n",
    "\n",
    "    #if no file already exists start the writing process\n",
    "    if not already_processed:\n",
    "\n",
    "        #list for holding file paths\n",
    "        list_of_files = []    \n",
    "\n",
    "        #get the path for all the email files\n",
    "        for path, subdirs, files in os.walk(origin):\n",
    "            for name in files:\n",
    "                list_of_files.append(os.path.join(path, name))\n",
    "\n",
    "        email_count = len(list_of_files)\n",
    "        #caluculate 1% of the number of files, used for progress report printing.\n",
    "        onepcofemail = (email_count//100)\n",
    "\n",
    "\n",
    "\n",
    "        #create dataframe to store data to be written\n",
    "        emails = pd.DataFrame()\n",
    "        print('Starting. {}'.format(time.strftime(\"%I:%M:%S\")))\n",
    "\n",
    "        #counter for testing batches\n",
    "        x = 0\n",
    "\n",
    "        #iterrate through all the files found\n",
    "        for i, myfile in enumerate(list_of_files):\n",
    "\n",
    "            #if running a testing session to break before reading all file to inspect the saved csv\n",
    "            if x > 6000 and testbool: break\n",
    "\n",
    "            #read individual email file\n",
    "            with open(myfile, 'r', encoding='utf-8', errors='replace') as filepath:\n",
    "                #read in the email\n",
    "                message=email.message_from_string(filepath.read())\n",
    "\n",
    "                #save the important components\n",
    "                emails.loc[i,'Message-ID']=message['Message-ID']\n",
    "                emails.loc[i,'from']=message['from']\n",
    "                emails.loc[i,'subject']=message['subject']\n",
    "                emails.loc[i,'to']=message['to']\n",
    "                emails.loc[i,'cc']=message['cc']\n",
    "                emails.loc[i,'bcc']=message['Bcc']\n",
    "                emails.loc[i,'date']=message['date']\n",
    "                emails.loc[i,'file']=message['X-FileName']\n",
    "\n",
    "                #check that the body is one or multiple sections and save it\n",
    "                if message.is_multipart():\n",
    "                    string = ''\n",
    "                    for payload in message.get_payload():\n",
    "                        print(payload.get_payload())\n",
    "                        string = string + payload.get_payload()\n",
    "                        emails.loc[i,'body'] = string\n",
    "                else:\n",
    "                    emails.loc[i,'body'] =  message.get_payload()\n",
    "\n",
    "            #append entry to the csv file\n",
    "            with open(destination, 'a') as f:\n",
    "                #if this is the first entry use the headers, if not, dont.True\n",
    "                if i == 0: emails.to_csv(f, header=emails.columns, index = False, sep=DELIMETER)\n",
    "                else: emails.to_csv(f, header=None, index = False, sep=DELIMETER)\n",
    "\n",
    "            #clear the dataframe to save memory\n",
    "            emails = pd.DataFrame()        \n",
    "\n",
    "            #print statement updating progress report\n",
    "            if i % onepcofemail == 0: \n",
    "                print('{}% finished. {}'.format(i//onepcofemail, time.strftime(\"%I:%M:%S\")), end=\"\\r\")\n",
    "\n",
    "            #itterate counter for testing batches\n",
    "            x = x+1\n",
    "\n",
    "\n",
    "        #process complete\n",
    "        print('Done! Exported {} lines to CSV {}'.format(x, time.strftime(\"%I:%M:%S\")))\n",
    "\n",
    "    #prints if the file already exists and there is no need to process the individual emails into a csv\n",
    "    else: print('****************File Previously Processed, Delete File to Process Again********************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************File Previously Processed, Delete File to Process Again********************\n"
     ]
    }
   ],
   "source": [
    "process_emails_into_df(root_path, saved_file, testing_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading File. 09:42:02\n",
      "File Loaded! 09:42:22\n"
     ]
    }
   ],
   "source": [
    "print('Loading File. {}'.format(time.strftime(\"%I:%M:%S\")))\n",
    "df = pd.read_csv(saved_file, sep=DELIMETER, engine='python')\n",
    "print('File Loaded! {}'.format(time.strftime(\"%I:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_small_senders(dataframe, min_email_count, new_file_dest):\n",
    "    path='/home/ubuntu/ssl/notebooks/' + new_file_dest\n",
    "    if not os.path.isfile(path): \n",
    "        unique_senders_inc_small = dataframe['from'].unique()\n",
    "        filtered_df = pd.DataFrame(columns = dataframe.columns)\n",
    "\n",
    "        for i, sender in enumerate(unique_senders_inc_small):\n",
    "            temp = dataframe[dataframe['from'] == sender]\n",
    "            print('{}% done'.format(round(i/len(unique_senders_inc_small)*100,2)) , end=\"\\r\")\n",
    "\n",
    "            if temp.shape[0] > min_email_count and '@enron.com' in sender:\n",
    "                filtered_df = filtered_df.append(temp, ignore_index = True)\n",
    "        filtered_df.to_csv(path, sep=DELIMETER, engine='python')\n",
    "    \n",
    "    else: \n",
    "        filtered_df = pd.read_csv(path, sep=DELIMETER, engine='python')\n",
    "        print('Loaded a previously processed csv, to reprocess delete {}'.format(new_file_dest))\n",
    "        \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a previously processed csv, to reprocess delete small_senders_filtered\n"
     ]
    }
   ],
   "source": [
    "new_df = filter_small_senders(df, 50, 'small_senders_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>to</th>\n",
       "      <th>cc</th>\n",
       "      <th>bcc</th>\n",
       "      <th>date</th>\n",
       "      <th>file</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>378377</th>\n",
       "      <td>378377</td>\n",
       "      <td>&lt;27555612.1075844385188.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>jeff.nogid@enron.com</td>\n",
       "      <td>Copies of ISDA documents</td>\n",
       "      <td>sara.shackleton@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fri, 11 Aug 2000 06:18:00 -0700 (PDT)</td>\n",
       "      <td>sshackle.nsf</td>\n",
       "      <td>Sara-\\n\\nAnnMarie Tiller has asked for:\\n\\n1) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378378</th>\n",
       "      <td>378378</td>\n",
       "      <td>&lt;10479620.1075844378616.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>jeff.nogid@enron.com</td>\n",
       "      <td>Issuer Forward Transactions</td>\n",
       "      <td>sara.shackleton@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mon, 24 Jul 2000 07:16:00 -0700 (PDT)</td>\n",
       "      <td>sshackle.nsf</td>\n",
       "      <td>Sara-\\n\\nHere is a term sheet from another pot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378379</th>\n",
       "      <td>378379</td>\n",
       "      <td>&lt;26219107.1075855402800.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>jeff.nogid@enron.com</td>\n",
       "      <td>FW: ENE equity swap for 6/18/01</td>\n",
       "      <td>sara.shackleton@enron.com, steve.ross@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue, 19 Jun 2001 07:28:11 -0700 (PDT)</td>\n",
       "      <td>sshackl (Non-Privileged).pst</td>\n",
       "      <td>Here is the new roll of this Equity Swap.\\n\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378380</th>\n",
       "      <td>378380</td>\n",
       "      <td>&lt;16324989.1075863201108.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>jeff.nogid@enron.com</td>\n",
       "      <td>FW: OTC physical expiration notice</td>\n",
       "      <td>sara.shackleton@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thu, 1 Nov 2001 08:33:48 -0800 (PST)</td>\n",
       "      <td>SSHACKL (Non-Privileged).pst</td>\n",
       "      <td>\\n\\n-----Original Message-----\\nFrom: Smoller,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378381</th>\n",
       "      <td>378381</td>\n",
       "      <td>&lt;29386777.1075858812938.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>jeff.nogid@enron.com</td>\n",
       "      <td>FW: Forward Amendment</td>\n",
       "      <td>sara.shackleton@enron.com</td>\n",
       "      <td>steve.ross@enron.com</td>\n",
       "      <td>steve.ross@enron.com</td>\n",
       "      <td>Fri, 21 Sep 2001 13:46:30 -0700 (PDT)</td>\n",
       "      <td>SSHACKL (Non-Privileged).pst</td>\n",
       "      <td>\\n\\n -----Original Message-----\\nFrom: \\tChris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                     Message-ID  \\\n",
       "378377      378377  <27555612.1075844385188.JavaMail.evans@thyme>   \n",
       "378378      378378  <10479620.1075844378616.JavaMail.evans@thyme>   \n",
       "378379      378379  <26219107.1075855402800.JavaMail.evans@thyme>   \n",
       "378380      378380  <16324989.1075863201108.JavaMail.evans@thyme>   \n",
       "378381      378381  <29386777.1075858812938.JavaMail.evans@thyme>   \n",
       "\n",
       "                        from                             subject  \\\n",
       "378377  jeff.nogid@enron.com            Copies of ISDA documents   \n",
       "378378  jeff.nogid@enron.com         Issuer Forward Transactions   \n",
       "378379  jeff.nogid@enron.com     FW: ENE equity swap for 6/18/01   \n",
       "378380  jeff.nogid@enron.com  FW: OTC physical expiration notice   \n",
       "378381  jeff.nogid@enron.com               FW: Forward Amendment   \n",
       "\n",
       "                                                     to                    cc  \\\n",
       "378377                        sara.shackleton@enron.com                   NaN   \n",
       "378378                        sara.shackleton@enron.com                   NaN   \n",
       "378379  sara.shackleton@enron.com, steve.ross@enron.com                   NaN   \n",
       "378380                        sara.shackleton@enron.com                   NaN   \n",
       "378381                        sara.shackleton@enron.com  steve.ross@enron.com   \n",
       "\n",
       "                         bcc                                   date  \\\n",
       "378377                   NaN  Fri, 11 Aug 2000 06:18:00 -0700 (PDT)   \n",
       "378378                   NaN  Mon, 24 Jul 2000 07:16:00 -0700 (PDT)   \n",
       "378379                   NaN  Tue, 19 Jun 2001 07:28:11 -0700 (PDT)   \n",
       "378380                   NaN   Thu, 1 Nov 2001 08:33:48 -0800 (PST)   \n",
       "378381  steve.ross@enron.com  Fri, 21 Sep 2001 13:46:30 -0700 (PDT)   \n",
       "\n",
       "                                file  \\\n",
       "378377                  sshackle.nsf   \n",
       "378378                  sshackle.nsf   \n",
       "378379  sshackl (Non-Privileged).pst   \n",
       "378380  SSHACKL (Non-Privileged).pst   \n",
       "378381  SSHACKL (Non-Privileged).pst   \n",
       "\n",
       "                                                     body  \n",
       "378377  Sara-\\n\\nAnnMarie Tiller has asked for:\\n\\n1) ...  \n",
       "378378  Sara-\\n\\nHere is a term sheet from another pot...  \n",
       "378379  Here is the new roll of this Equity Swap.\\n\\n ...  \n",
       "378380  \\n\\n-----Original Message-----\\nFrom: Smoller,...  \n",
       "378381  \\n\\n -----Original Message-----\\nFrom: \\tChris...  "
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = new_df.dropna(subset = ['to', 'cc', 'bcc'], how = 'all')\n",
    "new_df = new_df.dropna(subset = ['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(new_df, test_size= 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sender_recip_list(dataframe):\n",
    "    \n",
    "    #empty df for leading up addresses\n",
    "    sender_by_recip = pd.DataFrame(columns = ['sender','recipients', 'booksize'])\n",
    "    \n",
    "    #list of unique senders\n",
    "    unique_senders = dataframe['from'].unique()\n",
    "    \n",
    "    #arrays for holding values to be stored\n",
    "    senders = []\n",
    "    recipients = []\n",
    "    addressbooksize = []\n",
    "    \n",
    "    #itterate through each unique email writer\n",
    "    for i, sender in enumerate(unique_senders):\n",
    "        \n",
    "        #make a list of the samples from this itterations sender\n",
    "        users_emails = dataframe[dataframe['from'] == sender]\n",
    "        \n",
    "        all_recips = users_emails['to'].tolist() + users_emails['cc'].tolist() + users_emails['bcc'].tolist() \n",
    "        \n",
    "        \n",
    "        \n",
    "        senders.append(sender)\n",
    "        \n",
    "        name = []\n",
    "        for l in all_recips:\n",
    "            if not isinstance(l, str): pass\n",
    "            else: \n",
    "                l = l.replace('\\t','').replace('\\n','')\n",
    "                name.append(l.split(','))\n",
    "        \n",
    "        name = [item for sublist in name for item in sublist]\n",
    "        name = [item for sublist in name for item in sublist]\n",
    "        unique_recips = list(set(name))\n",
    "        recipients.append(unique_recips)\n",
    "        \n",
    "        addressbooksize.append(len(unique_recips))\n",
    "        \n",
    "        print('{}% done'.format(round(i/len(unique_senders)*100,2)) , end=\"\\r\")\n",
    "    \n",
    "    sender_by_recip['sender'] = senders\n",
    "    sender_by_recip['recipients'] = recipients\n",
    "    sender_by_recip['booksize'] = addressbooksize\n",
    "    return sender_by_recip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.89% done\r"
     ]
    }
   ],
   "source": [
    "senders_to = get_sender_recip_list(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_idfs(addressbook, emails):\n",
    "    tfidfv = TfidfVectorizer(min_df=1)\n",
    "    if not os.path.isfile('/home/ubuntu/ssl/notebooks/meaned_tf'):\n",
    "        unique_senders = addressbook['sender'].unique()\n",
    "\n",
    "        senders = []\n",
    "        recipients = []\n",
    "        tf_idf_body = []\n",
    "\n",
    "        for i, sender in enumerate(unique_senders):\n",
    "            this_guys_recips = addressbook[addressbook['sender'] == sender].recipients\n",
    "            this_guys_recips = [item for sublist in this_guys_recips for item in sublist]\n",
    "            for j, name in enumerate(this_guys_recips):\n",
    "                recip = name.strip(' ')\n",
    "                combo_s_r = emails[(emails['from']==sender) & \n",
    "                             ((emails['to'].str.contains(recip)) | \n",
    "                              (emails['cc'].str.contains(recip)) | \n",
    "                              (emails['bcc'].str.contains(recip)))]\n",
    "                print('{} / {} senders of {} / {} recipients done'.format(\n",
    "                                                        i, len(unique_senders),\n",
    "                                                        j, len(this_guys_recips)\n",
    "                                                        ), end=\"\\r\")\n",
    "                senders.append(sender)\n",
    "                recipients.append(recip)\n",
    "                tf_idf_body.append(np.mean(tfidfv.fit_transform(combo_s_r.body)))\n",
    "\n",
    "        meaned_tf = pd.DataFrame(columns = ['sender', 'recipient', 'mean_tf_idf'])\n",
    "        meaned_tf['sender'] = senders\n",
    "        meaned_tf['recipient'] = recipients\n",
    "        meaned_tf['mean_tf_idf'] = tf_idf_body\n",
    "        \n",
    "        print('Saving CSV, please wait.')\n",
    "        meaned_tf.to_csv('/home/ubuntu/ssl/notebooks/meaned_tf')\n",
    "        \n",
    "    else: \n",
    "        print('There is already a processed and saved file, delete it to repeat process. Loading File!')\n",
    "        meaned_tf = pd.read_csv('/home/ubuntu/ssl/notebooks/meaned_tf')\n",
    "    return meaned_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 01:31:16\n",
      "7 / 922 senders of 31 / 41 recipients done\r"
     ]
    }
   ],
   "source": [
    "print('Starting {}'.format(time.strftime(\"%I:%M:%S\")))\n",
    "meaned_idf = calc_mean_idfs(senders_to, new_df)\n",
    "print('Finished {}'.format(time.strftime(\"%I:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
